{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'deform_conv_ext' from partially initialized module 'models.basicVSR' (most likely due to a circular import) (/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/__init__.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m sys\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mappend(\u001b[39m'\u001b[39m\u001b[39m/Users/vchester/Documents/school/MBAn/6.8300/6.8300-Computer-Vision/src\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mdata_handlers\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mloading\u001b[39;00m \u001b[39mimport\u001b[39;00m VideoDataset\n\u001b[0;32m---> 16\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39mmodels\u001b[39;00m \u001b[39mimport\u001b[39;00m iconVSR\n\u001b[1;32m     18\u001b[0m device \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mdevice(\u001b[39m\"\u001b[39m\u001b[39mcuda\u001b[39m\u001b[39m\"\u001b[39m \u001b[39mif\u001b[39;00m torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available() \u001b[39melse\u001b[39;00m \u001b[39m\"\u001b[39m\u001b[39mcpu\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[1;32m     20\u001b[0m logging\u001b[39m.\u001b[39minfo(\u001b[39m\"\u001b[39m\u001b[39mStarting main training script\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mbasicVSR\u001b[39;00m \u001b[39mimport\u001b[39;00m basicVSR, BasicVSRPlusPlus, MultiStageBasicVSR, MultiStageBasicVSRAnalysis, MultiStageBasicVSRBN, MultiStageBasicMhead, iconVSR\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/__init__.py:8\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmultistagebasicvsr_model_bn\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiStageBasicVSRBN\n\u001b[1;32m      7\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmultistagebasicvsr_model_mhead\u001b[39;00m \u001b[39mimport\u001b[39;00m MultiStageBasicMhead\n\u001b[0;32m----> 8\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39miconvsr_model\u001b[39;00m \u001b[39mimport\u001b[39;00m iconVSR\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/iconvsr_model.py:12\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39moptical_flow\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mSPyNet\u001b[39;00m \u001b[39mimport\u001b[39;00m SPyNet, get_spynet\n\u001b[1;32m     11\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m\u001b[39mmodules\u001b[39;00m \u001b[39mimport\u001b[39;00m PixelShuffle, ResidualBlocksWithInputConv, flow_warp, ResidualBlockNoBN, TSAFusion, PCDAlignment, PredeblurModule, make_layer\n\u001b[0;32m---> 12\u001b[0m \u001b[39mfrom\u001b[39;00m \u001b[39m.\u001b[39;00m \u001b[39mimport\u001b[39;00m deform_conv_ext\n\u001b[1;32m     13\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mlogging\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[39mclass\u001b[39;00m \u001b[39miconVSR\u001b[39;00m(nn\u001b[39m.\u001b[39mModule):\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'deform_conv_ext' from partially initialized module 'models.basicVSR' (most likely due to a circular import) (/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/__init__.py)"
     ]
    }
   ],
   "source": [
    "import logging\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import torch\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.autograd import Variable\n",
    "\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append('/Users/vchester/Documents/school/MBAn/6.8300/6.8300-Computer-Vision/src')\n",
    "\n",
    "from data_handlers.loading import VideoDataset\n",
    "from models import iconVSR\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "logging.info(\"Starting main training script\")\n",
    "\n",
    "logging.info(\"Loading test data\")\n",
    "\n",
    "test_dataset = VideoDataset(\n",
    "    lr_data_dir='../data/processed/train/train_sharp_bicubic/X4',\n",
    "    hr_data_dir='../data/processed/train/train_sharp',\n",
    "    rolling_window=5,\n",
    "    is_test=True,\n",
    "    skip_frames=1\n",
    ")\n",
    "\n",
    "logging.debug(f\"Creating train and test dataloaders\")\n",
    "\n",
    "test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "model = iconVSR(\n",
    "    spynet_pretrained='../checkpoints/spynet_20210409-c6c1bd09.pth',\n",
    "    reset_spynet=False,\n",
    "    optical_flow_module='SPYNET',\n",
    ").to(device)\n",
    "criterion_mse = nn.MSELoss().to(device)\n",
    "max_epoch = 1\n",
    "model.eval()\n",
    "\n",
    "# os.makedirs(f'{config[\"result_dir\"]}/models', exist_ok=True)\n",
    "# os.makedirs(f'{config[\"result_dir\"]}/images', exist_ok=True)\n",
    "\n",
    "logging.info(\"Starting testing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'deform_conv_ext' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[12], line 6\u001b[0m\n\u001b[1;32m      4\u001b[0m gt_sequences \u001b[39m=\u001b[39m gt_sequences\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m      5\u001b[0m gt_sequences \u001b[39m=\u001b[39m gt_sequences\u001b[39m.\u001b[39msqueeze(\u001b[39m1\u001b[39m)\n\u001b[0;32m----> 6\u001b[0m pred_sequences \u001b[39m=\u001b[39m model(lq_sequences)\n\u001b[1;32m      7\u001b[0m \u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/computer_vision/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/iconvsr_model.py:252\u001b[0m, in \u001b[0;36miconVSR.forward\u001b[0;34m(self, lrs)\u001b[0m\n\u001b[1;32m    249\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, lrs):\n\u001b[1;32m    250\u001b[0m     n, t, c, h, w \u001b[39m=\u001b[39m lrs\u001b[39m.\u001b[39msize()\n\u001b[0;32m--> 252\u001b[0m     outputs_forward, outputs_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mforward_core(lrs)\n\u001b[1;32m    254\u001b[0m     \u001b[39m# upsampling\u001b[39;00m\n\u001b[1;32m    255\u001b[0m     outputs \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/iconvsr_model.py:204\u001b[0m, in \u001b[0;36miconVSR.forward_core\u001b[0;34m(self, lrs)\u001b[0m\n\u001b[1;32m    202\u001b[0m \u001b[39m# compute optical flow\u001b[39;00m\n\u001b[1;32m    203\u001b[0m flows_forward, flows_backward \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mcompute_flow(lrs)\n\u001b[0;32m--> 204\u001b[0m refill_feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mextract_refill_features(lrs, keyframe_idx)\n\u001b[1;32m    206\u001b[0m \u001b[39m# backward-time propagation\u001b[39;00m\n\u001b[1;32m    207\u001b[0m outputs_backward \u001b[39m=\u001b[39m []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/iconvsr_model.py:159\u001b[0m, in \u001b[0;36miconVSR.extract_refill_features\u001b[0;34m(self, lrs, keyframe_idx)\u001b[0m\n\u001b[1;32m    157\u001b[0m refill_feat \u001b[39m=\u001b[39m {}\n\u001b[1;32m    158\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m keyframe_idx:\n\u001b[0;32m--> 159\u001b[0m     refill_feat[i] \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49medvr(lrs[:, i:i \u001b[39m+\u001b[39;49m num_frame]\u001b[39m.\u001b[39;49mcontiguous())\n\u001b[1;32m    160\u001b[0m \u001b[39mreturn\u001b[39;00m refill_feat\n",
      "File \u001b[0;32m~/miniconda3/envs/computer_vision/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/iconvsr_model.py:379\u001b[0m, in \u001b[0;36mEDVRExtractor.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    374\u001b[0m \u001b[39mfor\u001b[39;00m i \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(t):\n\u001b[1;32m    375\u001b[0m     nbr_feat_l \u001b[39m=\u001b[39m [  \u001b[39m# neighboring feature list\u001b[39;00m\n\u001b[1;32m    376\u001b[0m         feat_l1[:, i, :, :, :]\u001b[39m.\u001b[39mclone(), feat_l2[:, i, :, :, :]\u001b[39m.\u001b[39mclone(),\n\u001b[1;32m    377\u001b[0m         feat_l3[:, i, :, :, :]\u001b[39m.\u001b[39mclone()\n\u001b[1;32m    378\u001b[0m     ]\n\u001b[0;32m--> 379\u001b[0m     aligned_feat\u001b[39m.\u001b[39mappend(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpcd_align(nbr_feat_l, ref_feat_l))\n\u001b[1;32m    380\u001b[0m aligned_feat \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mstack(aligned_feat, dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)  \u001b[39m# (n, t, c, h, w)\u001b[39;00m\n\u001b[1;32m    382\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mwith_tsa:\n",
      "File \u001b[0;32m~/miniconda3/envs/computer_vision/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/modules.py:227\u001b[0m, in \u001b[0;36mPCDAlignment.forward\u001b[0;34m(self, nbr_feat_l, ref_feat_l)\u001b[0m\n\u001b[1;32m    223\u001b[0m     offset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset_conv2[level](torch\u001b[39m.\u001b[39mcat(\n\u001b[1;32m    224\u001b[0m         [offset, upsampled_offset], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)))\n\u001b[1;32m    225\u001b[0m     offset \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mlrelu(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39moffset_conv3[level](offset))\n\u001b[0;32m--> 227\u001b[0m feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdcn_pack[level](nbr_feat_l[i \u001b[39m-\u001b[39;49m \u001b[39m1\u001b[39;49m], offset)\n\u001b[1;32m    228\u001b[0m \u001b[39mif\u001b[39;00m i \u001b[39m<\u001b[39m \u001b[39m3\u001b[39m:\n\u001b[1;32m    229\u001b[0m     feat \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfeat_conv[level](\n\u001b[1;32m    230\u001b[0m         torch\u001b[39m.\u001b[39mcat([feat, upsampled_feat], dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m))\n",
      "File \u001b[0;32m~/miniconda3/envs/computer_vision/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/modules.py:720\u001b[0m, in \u001b[0;36mDCNv2Pack.forward\u001b[0;34m(self, x, feat)\u001b[0m\n\u001b[1;32m    716\u001b[0m     logger \u001b[39m=\u001b[39m get_root_logger()\n\u001b[1;32m    717\u001b[0m     logger\u001b[39m.\u001b[39mwarning(\n\u001b[1;32m    718\u001b[0m         \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mOffset abs mean is \u001b[39m\u001b[39m{\u001b[39;00moffset_absmean\u001b[39m}\u001b[39;00m\u001b[39m, larger than 50.\u001b[39m\u001b[39m'\u001b[39m)\n\u001b[0;32m--> 720\u001b[0m \u001b[39mreturn\u001b[39;00m modulated_deform_conv(x, offset, mask, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias,\n\u001b[1;32m    721\u001b[0m                              \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mstride, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mpadding, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdilation,\n\u001b[1;32m    722\u001b[0m                              \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mgroups, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdeformable_groups)\n",
      "File \u001b[0;32m~/miniconda3/envs/computer_vision/lib/python3.9/site-packages/torch/autograd/function.py:506\u001b[0m, in \u001b[0;36mFunction.apply\u001b[0;34m(cls, *args, **kwargs)\u001b[0m\n\u001b[1;32m    503\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m torch\u001b[39m.\u001b[39m_C\u001b[39m.\u001b[39m_are_functorch_transforms_active():\n\u001b[1;32m    504\u001b[0m     \u001b[39m# See NOTE: [functorch vjp and autograd interaction]\u001b[39;00m\n\u001b[1;32m    505\u001b[0m     args \u001b[39m=\u001b[39m _functorch\u001b[39m.\u001b[39mutils\u001b[39m.\u001b[39munwrap_dead_wrappers(args)\n\u001b[0;32m--> 506\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39msuper\u001b[39;49m()\u001b[39m.\u001b[39;49mapply(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)  \u001b[39m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m    508\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mcls\u001b[39m\u001b[39m.\u001b[39msetup_context \u001b[39m==\u001b[39m _SingleLevelFunction\u001b[39m.\u001b[39msetup_context:\n\u001b[1;32m    509\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mRuntimeError\u001b[39;00m(\n\u001b[1;32m    510\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mIn order to use an autograd.Function with functorch transforms \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    511\u001b[0m         \u001b[39m'\u001b[39m\u001b[39m(vmap, grad, jvp, jacrev, ...), it must override the setup_context \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    512\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mstaticmethod. For more details, please see \u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    513\u001b[0m         \u001b[39m'\u001b[39m\u001b[39mhttps://pytorch.org/docs/master/notes/extending.func.html\u001b[39m\u001b[39m'\u001b[39m)\n",
      "File \u001b[0;32m/Data/reds_dataset/6.8300-Computer-Vision/src/models/basicVSR/modules.py:556\u001b[0m, in \u001b[0;36mModulatedDeformConvFunction.forward\u001b[0;34m(ctx, input, offset, mask, weight, bias, stride, padding, dilation, groups, deformable_groups)\u001b[0m\n\u001b[1;32m    553\u001b[0m output \u001b[39m=\u001b[39m \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mnew_empty(\n\u001b[1;32m    554\u001b[0m     ModulatedDeformConvFunction\u001b[39m.\u001b[39m_infer_shape(ctx, \u001b[39minput\u001b[39m, weight))\n\u001b[1;32m    555\u001b[0m ctx\u001b[39m.\u001b[39m_bufs \u001b[39m=\u001b[39m [\u001b[39minput\u001b[39m\u001b[39m.\u001b[39mnew_empty(\u001b[39m0\u001b[39m), \u001b[39minput\u001b[39m\u001b[39m.\u001b[39mnew_empty(\u001b[39m0\u001b[39m)]\n\u001b[0;32m--> 556\u001b[0m deform_conv_ext\u001b[39m.\u001b[39mmodulated_deform_conv_forward(\n\u001b[1;32m    557\u001b[0m     \u001b[39minput\u001b[39m, weight, bias, ctx\u001b[39m.\u001b[39m_bufs[\u001b[39m0\u001b[39m], offset, mask, output,\n\u001b[1;32m    558\u001b[0m     ctx\u001b[39m.\u001b[39m_bufs[\u001b[39m1\u001b[39m], weight\u001b[39m.\u001b[39mshape[\u001b[39m2\u001b[39m], weight\u001b[39m.\u001b[39mshape[\u001b[39m3\u001b[39m], ctx\u001b[39m.\u001b[39mstride,\n\u001b[1;32m    559\u001b[0m     ctx\u001b[39m.\u001b[39mstride, ctx\u001b[39m.\u001b[39mpadding, ctx\u001b[39m.\u001b[39mpadding, ctx\u001b[39m.\u001b[39mdilation, ctx\u001b[39m.\u001b[39mdilation,\n\u001b[1;32m    560\u001b[0m     ctx\u001b[39m.\u001b[39mgroups, ctx\u001b[39m.\u001b[39mdeformable_groups, ctx\u001b[39m.\u001b[39mwith_bias)\n\u001b[1;32m    561\u001b[0m \u001b[39mreturn\u001b[39;00m output\n",
      "\u001b[0;31mNameError\u001b[0m: name 'deform_conv_ext' is not defined"
     ]
    }
   ],
   "source": [
    "for idx, data in enumerate(test_loader):\n",
    "    gt_sequences, lq_sequences = data[1], data[0]\n",
    "    lq_sequences = lq_sequences.to(device)\n",
    "    gt_sequences = gt_sequences.to(device)\n",
    "    gt_sequences = gt_sequences.squeeze(1)\n",
    "    pred_sequences = model(lq_sequences)\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
