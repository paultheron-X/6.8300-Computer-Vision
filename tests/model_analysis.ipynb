{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import logging\n",
    "from torch.utils.data import DataLoader\n",
    "import torch\n",
    "import numpy as np\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "sys.path.append('/Data/reds_dataset/6.8300-Computer-Vision/src/')\n",
    "\n",
    "from data_handlers.loading import MultiStageVideoDataset\n",
    "from models import MultiStageBasicVSRAnalysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_dataset = MultiStageVideoDataset(\n",
    "        lr_data_dir='/Data/reds_dataset/6.8300-Computer-Vision/data/processed/train/train_sharp_bicubic/X4',\n",
    "        hr_data_dir='/Data/reds_dataset/6.8300-Computer-Vision/data/processed/train/train_sharp',\n",
    "        rolling_window=5,\n",
    "        is_test=False,\n",
    "        is_val=True,\n",
    "        patch_size=64,\n",
    "    )\n",
    "val_loader = DataLoader(val_dataset, batch_size=1, shuffle=False, num_workers=4)\n",
    "\n",
    "model = MultiStageBasicVSRAnalysis(\n",
    "        spynet_pretrained='/Data/reds_dataset/6.8300-Computer-Vision/checkpoints/spynet_20210409-c6c1bd09.pth',\n",
    "        pretrained_bvsr='/Data/reds_dataset/6.8300-Computer-Vision/checkpoints/basicvsr_custom_spynet.pth',\n",
    "        rolling_window=5,\n",
    "    )\n",
    "\n",
    "state_dict = torch.load('/Data/reds_dataset/6.8300-Computer-Vision/results_best/multistage_bvsr_trial_fixed/models/model_20.pth')\n",
    "state_dict = {k.replace('_orig_mod.',''): v for k, v in state_dict.items()}\n",
    "\n",
    "model.load_state_dict(state_dict)\n",
    "model = model.to('cuda')\n",
    "\n",
    "model = model.eval()\n",
    "model = model.requires_grad_(False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fri May 12 19:57:54 2023       \n",
      "+-----------------------------------------------------------------------------+\n",
      "| NVIDIA-SMI 525.60.11    Driver Version: 525.60.11    CUDA Version: 12.0     |\n",
      "|-------------------------------+----------------------+----------------------+\n",
      "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
      "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
      "|                               |                      |               MIG M. |\n",
      "|===============================+======================+======================|\n",
      "|   0  NVIDIA GeForce ...  Off  | 00000000:01:00.0 Off |                  N/A |\n",
      "| 30%   43C    P2    94W / 350W |    815MiB / 24576MiB |      4%      Default |\n",
      "|                               |                      |                  N/A |\n",
      "+-------------------------------+----------------------+----------------------+\n",
      "                                                                               \n",
      "+-----------------------------------------------------------------------------+\n",
      "| Processes:                                                                  |\n",
      "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
      "|        ID   ID                                                   Usage      |\n",
      "|=============================================================================|\n",
      "|    0   N/A  N/A      2111      G   /usr/bin/X                         57MiB |\n",
      "|    0   N/A  N/A      2167      G   /usr/bin/gnome-shell               31MiB |\n",
      "|    0   N/A  N/A     26619      C   ...omputer_vision/bin/python      722MiB |\n",
      "+-----------------------------------------------------------------------------+\n"
     ]
    }
   ],
   "source": [
    "!nvidia-smi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# criterion = CharbonnierLoss()\n",
    "device = 'cuda'\n",
    "psnrs = []\n",
    "psnrs_bis = []\n",
    "mse = nn.MSELoss()\n",
    "\n",
    "for idx, data in enumerate(val_loader):\n",
    "    gt_sequences, lq_sequences = data[1], data[0]\n",
    "    gt_sequences = gt_sequences.to(device)\n",
    "    (in_1, in_2, in_3) = (lq_sequences[0].to(device), lq_sequences[1].to(device), lq_sequences[2].to(device))    \n",
    "    out, attention_output, M, (first_conv, second_conv, third_conv), res, (output_1, output_2, output_3), base = model((in_1, in_2, in_3))\n",
    "    gt_sequences = gt_sequences.squeeze(1)\n",
    "    loss = mse(out, gt_sequences)\n",
    "    loss_bis = mse(res, gt_sequences)\n",
    "    psnrs.append((10*torch.log(1/loss)/torch.log(torch.Tensor([10]).to('cuda'))).cpu().detach().numpy())\n",
    "    psnrs_bis.append((10*torch.log(1/loss_bis)/torch.log(torch.Tensor([10]).to('cuda'))).cpu().detach().numpy())\n",
    "print(f'Average validation PSNR: {np.mean(psnrs)}dB')\n",
    "print(f'Average validation PSNR: {np.mean(psnrs_bis)}dB')\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Attention output analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([64, 180, 320])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attention_output = attention_output.squeeze()\n",
    "attention_output.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the 16 first channels of the attention output\n",
    "att_subset = attention_output[:16, :, :].permute(1, 2, 0).cpu().detach().numpy()\n",
    "\n",
    "fig, axs = plt.subplots(4, 4, figsize=(20, 20))\n",
    "for i in range(4):\n",
    "    for j in range(4):\n",
    "        axs[i, j].imshow(att_subset[:, :, i*4+j])\n",
    "        axs[i, j].set_title(f'Attention map {i*4+j}')\n",
    "        axs[i, j].axis('off')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Analysis of the attention masks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 180, 320])\n"
     ]
    }
   ],
   "source": [
    "M = M.squeeze()\n",
    "M_1 = M[0]\n",
    "M_2 = M[1]\n",
    "M_3 = M[2]\n",
    "\n",
    "first_conv_ = first_conv.squeeze(0).squeeze(0)\n",
    "second_conv_ = second_conv.squeeze(0).squeeze(0)\n",
    "third_conv_ = third_conv.squeeze(0).squeeze(0)\n",
    "\n",
    "output_1_ = output_1.squeeze(0)\n",
    "output_2_ = output_2.squeeze(0)\n",
    "output_3_ = output_3.squeeze(0)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([3, 64, 180, 320])\n",
      "torch.Size([3, 64, 180, 320])\n"
     ]
    }
   ],
   "source": [
    "input_cat = torch.cat(\n",
    "            [output_1_.unsqueeze(0), output_2_.unsqueeze(0), output_3_.unsqueeze(0)], dim=0\n",
    ")\n",
    "\n",
    "# calculate the pointwise multiplication of the attention masks with the input\n",
    "elemwise_mult = torch.mul(M, input_cat)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# print on 4 columns, (output, conv, M, M*output)\n",
    "# do 3 groups of 3 lines (one line for each stage), and one group for 4 different channels\n",
    "fig, axs = plt.subplots(9, 4, figsize=(20, 20))\n",
    "for i in range(0, 9, 3):\n",
    "    axs[i, 0].imshow(output_1_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i, 0].set_title(f'Output 1, channel {i}')\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 1].imshow(first_conv_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i, 1].set_title(f'Conv 1, channel {i}')\n",
    "    axs[i, 1].axis('off')\n",
    "    axs[i, 2].imshow(M_1[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i, 2].set_title(f'M 1, channel {i}')\n",
    "    axs[i, 2].axis('off')\n",
    "    axs[i, 3].imshow((elemwise_mult[0][i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy()))\n",
    "    axs[i, 3].set_title(f'M*output 1, channel {i}')\n",
    "    axs[i, 3].axis('off')\n",
    "    \n",
    "    axs[i+1, 0].imshow(output_2_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+1, 0].set_title(f'Output 2, channel {i}')\n",
    "    axs[i+1, 0].axis('off')\n",
    "    axs[i+1, 1].imshow(second_conv_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+1, 1].set_title(f'Conv 2, channel {i}')\n",
    "    axs[i+1, 1].axis('off')\n",
    "    axs[i+1, 2].imshow(M_2[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+1, 2].set_title(f'M 2, channel {i}')\n",
    "    axs[i+1, 2].axis('off')\n",
    "    axs[i+1, 3].imshow((elemwise_mult[1][i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy()))\n",
    "    axs[i+1, 3].set_title(f'M*output 2, channel {i}')\n",
    "    axs[i+1, 3].axis('off')\n",
    "    \n",
    "    axs[i+2, 0].imshow(output_3_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+2, 0].set_title(f'Output 3, channel {i}')\n",
    "    axs[i+2, 0].axis('off')\n",
    "    axs[i+2, 1].imshow(second_conv_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+2, 1].set_title(f'Conv 3, channel {i}')\n",
    "    axs[i+2, 1].axis('off')\n",
    "    axs[i+2, 2].imshow(M_3[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i+2, 2].set_title(f'M 3, channel {i}')\n",
    "    axs[i+2, 2].axis('off')\n",
    "    axs[i+2, 3].imshow((elemwise_mult[2][i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy()))\n",
    "    axs[i+2, 3].set_title(f'M*output 3, channel {i}')\n",
    "    axs[i+2, 3].axis('off')    \n",
    "    \n",
    "    \n",
    "   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the residuals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#plot the res in 3 colors\n",
    "res_ = res.squeeze(0)\n",
    "plt.imshow(res_.permute(1,2,0).cpu().detach().numpy())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_img = model.img_upsample(in_1[:, 2, :, :, :])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "upsampled_img = upsampled_img.squeeze(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(3, 2, figsize=(20, 20))\n",
    "for i in range(3):\n",
    "    axs[i, 0].imshow(upsampled_img[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i, 0].set_title(f'Upsampled image, channel {i}')\n",
    "    axs[i, 0].axis('off')\n",
    "    axs[i, 1].imshow(res_[i].unsqueeze(0).permute(1,2,0).cpu().detach().numpy())\n",
    "    axs[i, 1].set_title(f'Residual, channel {i}')\n",
    "    axs[i, 1].axis('off')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "computer_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
